include=secor.common.properties

############
# MUST SET #
############

# Fill the section which fits your needs
###############
#  Using S3   #
###############

# Name of the s3 bucket where log files are stored.
secor.s3.bucket=

###############
# Using Swift #
###############

# Boolean variable which determines if each topic will be uploaded to different container
# (Created automatic) - if true the next setting will be ignored
secor.swift.containers.for.each.topic=false

# Name of swift container where log files are stored.
secor.swift.container=logsContainer

################
# END MUST SET #
################

kafka.seed.broker.host=localhost
kafka.seed.broker.port=9092

zookeeper.quorum=localhost:2181

# Upload policies.
# 10K
secor.max.file.size.bytes=10000
# 1 minute
secor.max.file.age.seconds=60

# Info container for ParquetFactoryReaderWriter 
# in this container there will be .schema files and .metaKeys files
# The schema is in Avro format
# the metaKeys is each key in row
secor.info.container=secorSchema

# Parquet options
secor.parquet.block_size=16777216
secor.parquet.page_size=65536

# SSL configurations (for supporting brokers)
kafka.security.protocol=SASL_SSL
kafka.ssl.protocol=TLSv1.2
kafka.ssl.enabled.protocols=TLSv1.2
kafka.ssl.truststore.location=/usr/lib/jvm/default-java/jre/lib/security/cacerts
kafka.ssl.truststore.password=changeit
kafka.ssl.truststore.type=JKS
kafka.ssl.endpoint.identification.algorithm=HTTPS
